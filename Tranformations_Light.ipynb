{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48067bd9-ae43-41dc-93a6-fa6b5c7291e8",
   "metadata": {},
   "source": [
    "# Analytics Best Practices - Staying Light on Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738a1b1a-bdf0-406f-b612-f66ea9761f77",
   "metadata": {},
   "source": [
    "This notebook illustrates a very simple yet powerful idea I've been exploring over the last couple of years.\n",
    "\n",
    "**The Key Idea**: Central data teams almost always struggle with the challenge of having\n",
    "\n",
    "- dozens of \"source domains\" inside their data structures, say \"orders\", \"customers\", ... all of which need a decent amount of knowledge\n",
    "to properly transform them into something useful\n",
    "- dozens of \"target domains\" like marketing, sales,... which again need special knowledge to transform source data into information\n",
    "fitting their needs.\n",
    "\n",
    "So at the center, the problem is that a **low number of central data teams (low compared to the number of source & target teams) needs\n",
    "to understand a multiple of other domains to get their work done**. In my opinion there are two options to solve this problem (once it \n",
    "becomes a true problem). \n",
    "1. Keep the domain stuff inside the domains => that's called \"distributed data domain ownership\" and is the first step towards a data mesh.\n",
    "2. <= focus of this piece: Pass the domains through as much as possible, be \"light on transformations\", if not completely possible, \n",
    "keep them as close to the endusers as possible.\n",
    "\n",
    "\n",
    "\n",
    "*Note: If many domains aren't a problem for you, then you probably don't need this! It's entirely fine to make stuff work. Usually that means\n",
    "you have well organized domains, or a low number of domains, or low complexity inside the domains. You might also chose to have \n",
    "\"one domain expert\" for the major domains, or you might chose to decentralize the analysis & possibly the transformation part of the work.\n",
    "All of which are organizational solutions to the problem.\n",
    "Here, I'm talking about a solution that works out-of-the-box for the existing centralized data team.*\n",
    "\n",
    "Enough talk, let's get started..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fb0810-cec0-4111-b0a3-02213a24e7ff",
   "metadata": {},
   "source": [
    "## Let's do some dependency magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5297e9cd-576c-4207-89e1-08f8cedcfde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (1.4.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.9/site-packages (from pandas) (1.22.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Let's get our dependencies\n",
    "import sys\n",
    "!{sys.executable} -m pip install pandas\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# some constants\n",
    "DATA_FILE_PATH=\"work/data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97221867-04fd-44cf-89a2-da6069fc4b2f",
   "metadata": {},
   "source": [
    "## Let's get started! With an Example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9cebd37b-7367-4c91-bbe1-4d40a4302adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is our dataframe...\n",
      "   CRMRep  day  Order Status\n",
      "0  James    1      1      A\n",
      "1  James    1      2      F\n",
      "2    Eve    2      3      A\n",
      "3    Bob    3      4      B\n",
      "4    Eve    4      5      A\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_FILE_PATH)\n",
    "print(\"This is our dataframe...\\n\", df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c5abe3-e90e-44aa-8acf-638e7d0d821b",
   "metadata": {},
   "source": [
    "This is our input data, the simplest possible I could find.\n",
    "\n",
    "**Our task** is to produce a dashboard for now just with one table. Our stakeholder would like to see...\n",
    "- The orders for each Sales Rep, for each of the status (A=ordered, B= shipped, F=returned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac96b912-cba4-4e03-b91f-243c471d157b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Order\n",
      "SalesRep Status         \n",
      "Bob      shipped       1\n",
      "Eve      ordered       2\n",
      "James    ordered       1\n",
      "         returned      1\n"
     ]
    }
   ],
   "source": [
    "## 1. First let's do some prettifying on the days, We're in 2022 in the month 1, so we can actually\n",
    "## turn this into a proper date\n",
    "df['day'] = df['day'].apply(lambda x: datetime(2022,1,x)) \n",
    "\n",
    "\n",
    "## 2. That looks already much nicer... Next, let's tackle the order status, let's map that to its speaking name\n",
    "df['Status'] = df['Status'].apply(lambda x: \"ordered\" if x==\"A\" else (\"shipped\" if x==\"B\" else \"returned\"))\n",
    "\n",
    "\n",
    "## 3. The wording \"CRMRep\" isn't so nice, let's change that to the one used by the stakeholder \"Sales Rep\"\n",
    "df=df.rename(columns={\"CRMRep\": \"SalesRep\"})\n",
    "\n",
    "\n",
    "## 4. finally, we're going to do the groupying \n",
    "print(df.groupby(by=[\"SalesRep\", \"Status\"]).count().drop(columns=\"day\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1024c228-7ae7-4a31-a3d4-abbccd0436ba",
   "metadata": {},
   "source": [
    "### How This Could Be Improved by Staying Light on Transformation ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dea071-c6bd-4252-a224-d88d92566539",
   "metadata": {},
   "source": [
    "I'm going to teach you the idea of \"stay light on data transformations\" using the example above.\n",
    "\n",
    "**Problem 1**: In (1) we've done some really naive transformation, mapping the \"day\" into the year 2022, month 01 to \"prettify\" it. But as you might've already realized, this might break, once we reach another month. Of course the question is: How does the source data \n",
    "look like in Feb 2022? And the answer is: We probably don't know. Soooo... the solution?\n",
    "\n",
    "**The Solution?**: Try to avoid transformations, period. \n",
    "\n",
    "Let's remove this one, and see the obvious caveats to this one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da0f6f3e-0e27-4556-bf97-b691421415dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Order\n",
      "SalesRep Status         \n",
      "Bob      shipped       1\n",
      "Eve      ordered       2\n",
      "James    ordered       1\n",
      "         returned      1\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_FILE_PATH)\n",
    "\n",
    "## 1. We simply are not going to do the \"prettifying\". If the source tells us it's \"day 1\" we display it as day 1.\n",
    "\n",
    "## 2. That looks already much nicer... Next, let's tackle the order status, let's map that to its speaking name\n",
    "df['Status'] = df['Status'].apply(lambda x: \"ordered\" if x==\"A\" else (\"shipped\" if x==\"B\" else \"returned\"))\n",
    "\n",
    "\n",
    "## 3. The wording \"CRMRep\" isn't so nice, let's change that to the one used by the stakeholder \"Sales Rep\"\n",
    "df=df.rename(columns={\"CRMRep\": \"SalesRep\"})\n",
    "\n",
    "\n",
    "## 4. finally, we're going to do the groupying \n",
    "print(df.groupby(by=[\"SalesRep\", \"Status\"]).count().drop(columns=\"day\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d6402a-805e-41f3-9127-0f83d22e69c7",
   "metadata": {},
   "source": [
    "**The benefits?**: First of all, stuff doesn't break. But in this case, we also removed complexity from our transformation,\n",
    "roughly 25% which is a lot in my opinion.\n",
    "\n",
    "Let's tackle the next problem.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0343494-b842-4b06-ae3f-120ebc82080d",
   "metadata": {},
   "source": [
    "**Problem 2**: In 2, we did another transformation, we mapped numbers to speaking names. This seems to be a necessary transformation or does it? The problem is, that our central data team writing these transformations usually isn't 100% up to speed with the semantics of the source domains. How could they, there are dozens of source domains for every data team in the typical company.\n",
    "\n",
    "So it will happen, that stuff changes. OR that the data team misses one order status (what about C,D,E?). Or that the source team decides to change \"A\" to \"reserved/put into basket\". \n",
    "\n",
    ". Soooo... the solution?\n",
    "\n",
    "**The Solution?**: Try to avoid transformation, as in (1). OR we could do something else, we could do the transformation, but do it \"close to the end-user\". In this case, we could simply display the transformation we chose to do such that a possible user can pick up on wrongly mapped statuses. \n",
    "\n",
    "(Alternative 2b: If we'd chosen to avoid this transformation, we would've followed the simple idea of \"keeping the semantics inside their domains\")\n",
    "\n",
    "Let's do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9f2d7e1a-f1f5-4b6c-b59a-be948f8a01ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Order\n",
      "SalesRep Status_speaking_name       \n",
      "Bob      shipped                   1\n",
      "Eve      ordered                   2\n",
      "James    ordered                   1\n",
      "         returned                  1\n",
      "We're using the following mapping table:   Status Status_speaking_name\n",
      "0      A              ordered\n",
      "1      B              shipped\n",
      "2      F             returned\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_FILE_PATH)\n",
    "\n",
    "## 1. We simply are not going to do the \"prettifying\". If the source tells us it's \"day 1\" we display it as day 1.\n",
    "\n",
    "## 2. That looks already much nicer... Next, let's tackle the order status, let's map that to its speaking name,\n",
    "## but this time we're going to make the transformation \"close to the end-user\"\n",
    "\n",
    "mapping = {'Status': [\"A\", \"B\",\"F\"], 'Status_speaking_name': [\"ordered\", \"shipped\",\"returned\"]}\n",
    "mapping_df = pd.DataFrame(data=mapping)\n",
    "#print(df)\n",
    "#print(mapping_df)\n",
    "\n",
    "joined_df = df.join(mapping_df.set_index(\"Status\"), on=\"Status\")\n",
    "\n",
    "## 3. The wording \"CRMRep\" isn't so nice, let's change that to the one used by the stakeholder \"Sales Rep\"\n",
    "joined_df=joined_df.rename(columns={\"CRMRep\": \"SalesRep\"})\n",
    "\n",
    "\n",
    "\n",
    "## 4. finally, we're going to do the groupying \n",
    "print(joined_df.groupby(by=[\"SalesRep\", \"Status_speaking_name\"]).count().drop(columns=[\"day\",\"Status\"]))\n",
    "print(\"We're using the following mapping table:\", mapping_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7e68fd-4a19-47d1-897f-579ae086caa8",
   "metadata": {},
   "source": [
    "**The benefits?**: Since we chose to still to a transformation, stuff might still break.\n",
    "But we did encapsulate the mapping logic into one table which reduces the complexity by decoupling this part. \n",
    "If we now get an order status \"C,D,E\" nothing breaks. In the first implementation it would break. Instead we would get a \"NULL\" which would \n",
    "signal exactly the right thing: The mapping is not complete.\n",
    "\n",
    "Second, we're making our transformation transparent which means every end-user can easily see what's going on and possibly\n",
    "correct us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2f0f49-b823-4b31-aa6c-92254219aa83",
   "metadata": {},
   "source": [
    "**Problem 3**: You noticed we renamed \"CRMRep\" to \"SalesRep\" because it was the language our stakeholder was using, and because it \n",
    "sounds so much better. And it does.\n",
    "\n",
    "Except, it's entirely possible (and has happened to me in the past) that suddenly marketing also starts to use the CRM System and suddenly\n",
    "there also is a \"MarketingRep\". Now \"SalesRep\" and \"MarketingRep\" are simply attributes of the CRMRep, and the CRMRep is still the CRMRep.\n",
    "\n",
    "**The key lesson here is:** There is always a reason a source team names things the way they do. Even if they don't have one,\n",
    "they will have one in the future. \n",
    "\n",
    "**The Solution**: The solution is another idea which is to \"stay close to the source\". Meaning we try to keep everything as it is on\n",
    "the source level, not just what we \"perceive as semantics\" (see problem 2). However we still might want to provide our endusers with a\n",
    "proper naming... So for this example we can have it both by providing transparency (see the pattern?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e76d7302-858a-42f9-957b-8d5d16c96c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    Order\n",
      "SalesRep Status_speaking_name source_name_SalesRep       \n",
      "Bob      shipped              CRMrep                    1\n",
      "Eve      ordered              CRMrep                    2\n",
      "James    ordered              CRMrep                    1\n",
      "         returned             CRMrep                    1\n",
      "We're using the following mapping table:   Status Status_speaking_name\n",
      "0      A              ordered\n",
      "1      B              shipped\n",
      "2      F             returned\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_FILE_PATH)\n",
    "\n",
    "## 1. We simply are not going to do the \"prettifying\". If the source tells us it's \"day 1\" we display it as day 1.\n",
    "\n",
    "## 2. That looks already much nicer... Next, let's tackle the order status, let's map that to its speaking name,\n",
    "## but this time we're going to make the transformation \"close to the end-user\"\n",
    "\n",
    "mapping = {'Status': [\"A\", \"B\",\"F\"], 'Status_speaking_name': [\"ordered\", \"shipped\",\"returned\"]}\n",
    "mapping_df = pd.DataFrame(data=mapping)\n",
    "\n",
    "joined_df = df.join(mapping_df.set_index(\"Status\"), on=\"Status\")\n",
    "\n",
    "## 3. The wording \"CRMRep\" isn't so nice, let's change that to the one used by the stakeholder \"Sales Rep\", This is the renaming \n",
    "## \"module\"\n",
    "joined_df=joined_df.rename(columns={\"CRMRep\": \"SalesRep\"})\n",
    "joined_df['source_name_SalesRep'] = \"CRMrep\"\n",
    "\n",
    "\n",
    "## 4. finally, we're going to do the groupying \n",
    "agg_df = joined_df.groupby(by=[\"SalesRep\", \"Status_speaking_name\", \"source_name_SalesRep\"]).count().drop(columns=[\"day\",\"Status\"])\n",
    "\n",
    "\n",
    "print(agg_df)\n",
    "print(\"We're using the following mapping table:\", mapping_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3493b3be-9bf1-48bd-8f73-270c59214e7f",
   "metadata": {},
   "source": [
    "Wow! That looks different right? I hope the final example also shows you the three drivers of benefits.\n",
    "\n",
    "**Benefit drivers**: The benefits are driven through \n",
    "\n",
    "- transparency for end-users \n",
    "- transparency for data developers\n",
    "- reduction of complexity by decoupling for end-users\n",
    "- reduction of complexity by decouplting for developers\n",
    "\n",
    "**Benefits explained for Solution 3**:\n",
    "\n",
    "By making the source name transparent, endusers know what this column is referring to in the CRM system. If the change in the CRM system is \n",
    "proposed, they might even raise the issue of \"breaking reports & dashboards\". Or they might not. But they will surely know how to fix it.\n",
    "\n",
    "By making this transparent to the developers, even someone who never touched this pipeline can see, with a look onto the dashboard,\n",
    "what might be broken if suddenly \"Marketing Reps\" appear in the SalesRep column.\n",
    "\n",
    "Finally, by decoupling this logic into a \"3\" block, we got a nicely wrapped decoupled part for renaming. It's now easy to stuff\n",
    "all renaming into this block."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f2d025-6847-45a6-b855-a6147a6b8f5a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
